---
title: "The weather outside is frightfull"
description: |
  National Weather Service fatality records
author:
  - name: David Fox
date: 07-21-2020
output:
  distill::distill_article:
    self_contained: false
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(tidyverse)
library(here)
library(hrbrthemes)
library(lubridate)
library(pdftools)
library(readr)
library(rJava)
library(tabulizer)
library(janitor)
library(gt)
library(ggridges)
library(ggdist)
library(ggalt)
library(viridisLite)
theme_set(theme_ipsum_rc())
```

## Weather fatalities.

This post was inspired by this chart tweeted out by my local NWS office. Let me say off the bat that I have a very high regard for what the National Weather Service does (put down the sharpie), but this data visualization left me a bit --- unsatisfied.

```{r, layout="l-body-outset"}
knitr::include_graphics(here("_posts/2020-07-21-the-weather-outside-is-frightfull/nws_chart.jpg"))
```

Wanting to see if I could take a stab at doing something different, I was surprised to quickly find the [data](https://www.weather.gov/hazstat/) -- however only available in a PDF. This seemed like a good time to work on my PDF extraction skills.

Thomas Mock recently outlined a method for scrapping pdf's on his [blog](https://themockup.netlify.app/posts/2020-04-03-beer-and-pdftools-a-vignette/). I tried what he outlined - but was still getting some rough results.

I also tried the {[tabulizer](https://github.com/ropensci/tabulizer)} package as detailed [here.](https://www.business-science.io/code-tools/2019/09/23/tabulizer-pdf-scraping.html) With apologies to Thomas, this was easier - although I had so do some gyrations to deal with the table being split over two pages. Edward Tufte has been credited with the phrase "chart junk" which describes unnecessary or downright confusing "extras" added to charts, often obscuring the fact that they would be better off as a table. This NWS chart is suffering a slight case of chart junk, but I wonder if there is an equivalent phrase to capture what is going on in this table, with extra comments in what should be columns, as well as column names showing up again at the bottom of the table on the seconds page.

```{r tablulizer, echo=TRUE, layout="l-body-outset", cache=TRUE}
pdf = here("_posts/2020-07-21-the-weather-outside-is-frightfull/80years.pdf")

table_scrape <-  extract_tables(file = pdf,
                                method = "decide",
                                output ="matrix")

#bind_rows was being quite picky here, so rbind it is
joined_table_scrape = rbind(table_scrape[[1]],table_scrape[[2]])

#get the first rows for names
col_names = joined_table_scrape %>% as_tibble() %>%  slice(1)

#rename the columns and drop some of the table trappings
weather_df = joined_table_scrape %>%
  as_tibble() %>% 
  set_names(col_names) %>% 
  slice(3:83) %>% 
  slice(-45)
```

We now have the equivalent of the PDF table, minus some of the extra bits, but there are still some comments hanging out in our data, and we have some janky column names.

```{r}
weather_df %>% head() %>% gt()
```

I'll use the excellent {[janitor](http://sfirke.github.io/janitor/index.html)} package to clean up the column names, a little regex to get the text out of the all_events column, and then convert all columns to numeric with the new 'across' verb in {dplyr}.

```{r echo=TRUE}
weather_cleaned = weather_df %>%
  clean_names() %>% 
  rename(damages_millions = all_hazard, all_events = all_wx) %>% 
  mutate(all_events = str_remove_all(all_events, "[:alpha:]|[:punct:]"),
         damages_millions = as.double(str_remove_all(damages_millions, "[$|,]"))) %>% 
  mutate(across(where(is.character), as.numeric)) 
```

Now that was a lot of trouble for a simple data table. First, let's recreate the NWS chart (minus the 3D). This will require some summary stats for the - somewhat arbitrary - time periods compared.

```{r echo=TRUE}
wx_2019 = weather_cleaned %>%
  filter(year == 2019) %>% 
  mutate(year = as.character(year))

wx_10year = weather_cleaned %>%
  filter(year>= 2010) %>%
  summarise(across(lightning:all_events, mean, na.rm = TRUE)) %>% 
  mutate(year = '10year_avg')

wx_30year = weather_cleaned %>%
  filter(year>= 1990) %>%
  summarise(across(lightning:all_events, mean, na.rm = TRUE)) %>% 
  mutate(year = '30year_avg')

wx_trends = bind_rows(wx_2019, wx_10year, wx_30year) %>%
  mutate(year = factor(year, levels = c("30year_avg", "10year_avg", "2019")))

wx_trends_long = wx_trends %>% 
  select(-damages_millions, -all_events) %>% 
  pivot_longer(cols= - year, names_to = 'hazard', values_to='fatalities')
```

### NWS Plot recreation.

I think there are a number of issues with the original chart, particularly the ordering of the time periods and the unsorted arrangement of the hazards, even the title is a bit confusing. Let's take a stab at these. I'll use the nice new ggplot function to offset the column names.

```{r, layout="l-body-outset"}
ggplot(wx_trends_long, aes(fct_reorder(hazard, fatalities), fatalities,  fill = year)) +
  geom_col(position = "dodge") +
  scale_fill_ipsum() +
  scale_fill_ipsum(labels = c("30 year avg", "10 year avg", "2019")) +
  scale_x_discrete(guide = guide_axis(n.dodge = 2)) +
  labs(title = "NWS weather related fatalities",
       caption  = "NWS",
       x = '',
       fill = '') +
  theme(legend.position = c(.2,.8), plot.title.position = "plot")
  
```

While an improvement, in my opinion, I think there are some better ways to tackle this information. One thing we could do is add decade trends, rather than these averages - which are inclusive; the 30 year average includes the 10 year average. But why not use all the data? We'll need to pivot the data to a longer, tidy format.

```{r}
weather_long = weather_cleaned %>%
  select(-damages_millions) %>% 
  pivot_longer(cols = c(-year), names_to = 'hazard', values_to = 'fatalities')
```

One way to approach this would be a faceted plot.

```{r,layout="l-body-outset", fig.height=8}
weather_long %>% filter(hazard != 'all_events') %>% 
  ggplot(aes(x= year, y = fatalities, color = fct_reorder(hazard, fatalities))) +
  geom_smooth(method = "gam", formula = y ~ s(x, bs = "tp"), se = FALSE) +
  geom_point(alpha = .5) +
  scale_y_sqrt() +
  scale_color_ipsum() +
  facet_wrap(~hazard, scales = "free_y") +
  scale_x_continuous(guide = guide_axis(n.dodge = 2)) +
  labs(title = "Annual trends in weather realated fatalities.",
       caption  ="NWS",
       x = NULL,
       y = 'fatalities') +
  theme(legend.position = 'null', plot.title.position = "plot")
       
  
```

Getting better - but how about some ridges?

```{r ridges, layout="l-body-outset", fig.height=6}
weather_long %>% filter(hazard != 'all_events') %>% 
  ggplot(aes(x= year, y = hazard, height = fatalities, fill = fct_reorder(hazard, fatalities))) +
  geom_density_ridges(stat="identity", alpha = .5) +
  scale_fill_ipsum() +
  labs(title = "Annual trends in weather realated fatalities.",
       caption  ="NWS",
       x = NULL,
       y = NULL) +
  theme(legend.position = 'null', plot.title.position = "plot")
```

I think you could make an argument for either of these plots. The faceted plot shows actual trends and data points, but the ridge plot gives a better comparison between the groups and shows that most of these patterns look stochastic. However lightning and rip currents are interesting. Lightning fatalities have dropped dramatically since the 1940s. If we were to make this a per capital rate the change would be even more dramatic. Speculatively - there may be many fewer people working in the agricultural sector that might be exposed to lightening, also increased weather forecasting may be playing a role - most of us are carrying around an up to date weather forecast in our our pockets.

```{r lightning, layout="l-body-outset", fig.height=6}
weather_long %>% filter(hazard == 'lightning') %>% 
  ggplot(aes(x= year, y = fatalities)) +
  geom_smooth(method= "gam") +
  geom_point(color = '#3f2d54', size =3, alpha = .7) +
  labs(title = "Fatalities attributed to lightening \nhave droped dramatically since the 1940's.",
       caption  ="NWS",
       x = NULL,
       y = 'fatalities') +
  theme(plot.title.position = "plot")
```

Fatalities related to rip current shows the opposite trend, a steep increase since this metric started to be measured in 2002. This increase is likely related to per capital swimming and beach going, rather than any increase in rip currents themselves. Still, be careful on the beach - I can attest from personal experience that being in a rip current is quite terrifying.

```{r rip, layout="l-body-outset", fig.height=6}
weather_long %>% filter(hazard == 'rip_curr') %>% 
  ggplot(aes(x= year, y = fatalities)) +
  geom_point(size = 3, color = '#d1ab75') +
  xlim(2000, 2019) + 
  geom_smooth(method = 'gam', se = TRUE) +
  labs(title = "Fatalities attributed to rip currents \nhave increased since data collection started in 2002.",
       caption  ="NWS",
       x = NULL,
       y = 'fatalities') +
  theme(plot.title.position = "plot")
```

We can also take a quick look at all hazard fatalities - which have trended flat, with the exceptions of some bad years. Never the less, let's be careful out there folks.

```{r all haz, layout="l-body-outset", fig.height=6}
weather_long %>% filter(hazard == 'all_events') %>% 
  ggplot(aes(x= year, y = fatalities, color = fatalities)) +
  geom_point(aes(size = fatalities), show.legend = FALSE) +
  geom_smooth(method = "gam", se = FALSE) +
  xlim(1985,2020) +
  labs(title = "With the exception of some bad years,\nweather related fatalities have been steady \nsince the 1980's.",
       caption  ="NWS",
       x = NULL,
       y = 'fatalities') +
  scale_color_viridis_c() +
  theme(plot.title.position = "plot", legend.position = 'null')
```
